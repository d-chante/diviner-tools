{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec81aa2-986f-487c-82de-d26f6a83df90",
   "metadata": {},
   "source": [
    "# Data Preprocess\n",
    "\n",
    "This Notebook instance provides a procedure to pre-process channel 7 Diviner data collected between January 2010 - September 2023 as part of a goal to replicate the work published in [Unsupervised Learning for Thermophysical Analysis on the Lunar Surface](https://iopscience.iop.org/article/10.3847/PSJ/ab9a52) by Moseley et al. (2020).\n",
    "\n",
    "A particular objective of this pre-processing notebook is to use only a standard computer (CPU, multi-threading) with augmented storage space (~5TB)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9d652-7b25-4fc4-8a04-2b6dafb0116d",
   "metadata": {},
   "source": [
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a07d66-c24c-45df-a95d-e54e205a74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diviner_tools import DivinerTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50a6a8-d81a-4ec8-bcc3-8bf9303eb9b5",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397672c7-737d-40a5-87cf-08855090e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathway to config file\n",
    "CFG_FILEPATH = \"/Notebooks/Moseley/diviner-tools/support/config/cfg.yaml\"\n",
    "\n",
    "# Pathway to pre-collected zip file URLs list\n",
    "ZIP_FILEPATH = \"/esthar/diviner_data/txt_files/zip_urls.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea59d42-d1dd-4e0f-ad5a-6c66d77f7569",
   "metadata": {},
   "source": [
    "#### Init Diviner Tools\n",
    "\n",
    "diviner_tools is a custom library developed specifically for this task. Upon initialization of the Diviner Tools object, it will create the data directory and database if they don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a28e4c-abd5-4a9e-9d20-67218c965873",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DivinerTools(CFG_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef546826-3ab3-4c4d-bf6f-ea1941ec4070",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "Preprocessing will involve:\n",
    "* Splitting the zip file URLs into batches\n",
    "* For each url, download the .zip file to local directory\n",
    "* Unpack the .zip file\n",
    "* Read the lines from the unpacked .TAB file\n",
    "* Check each line against desired criteria (activity flag, geoemetry flag, etc)\n",
    "* If a line meets the desired criteria, write it to our database\n",
    "* If a .TAB file contains data that was written to the database, save the filename to a textfile\n",
    "* Delete the .TAB file\n",
    "\n",
    "Since there is a lot of data to process which may take a long period of time, we will split the 717,509 URLs into parent batches of 100,000 each and will manually start each 100,000 master batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b51e34-66b9-45e7-afc4-31912a2a5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = dt.tab_to_lines(\"/esthar/diviner_data/tmp/201001010120_RDR.TAB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1176607a-463d-4da0-9e9f-1be9e07e41a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98448\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ok_lines = []\n",
    "\n",
    "for line in lines:\n",
    "    # Split the line    \n",
    "    values = line.strip().split(',')\n",
    "\n",
    "    # Remove any whitespaces from the values\n",
    "    values = [val.strip() for val in values]\n",
    "\n",
    "    # Check that the data conforms to desired params\n",
    "    dataok = dt.check_params(values)\n",
    "\n",
    "    if (dataok):\n",
    "        ok_lines.append(line)\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f444239-0fff-4b2e-ae76-02244592e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DATE': \"01-Jan-2010\"\n",
      "'UTC': \"01:20:00.022\"\n",
      "'JDATE': 2455197.555555820\n",
      "'ORBIT': 2368\n",
      "'SUNDIST': 0.98570\n",
      "'SUNLAT': -0.31138\n",
      "'SUNLON': 354.67220\n",
      "'SCLK': 0284001599.65208\n",
      "'SCLAT': 8.97501\n",
      "'SCLON': 263.43874\n",
      "'SCRAD': 1790.82210\n",
      "'SCALT': 53.60619\n",
      "'EL_CMD': 180.000\n",
      "'AZ_CMD': 240.000\n",
      "'AF': 110\n",
      "'ORIENTLAT': -0.91547\n",
      "'ORIENTATION': 173.69001\n",
      "'C': 7\n",
      "'DET': 1\n",
      "'VLOOKX': 0.078868\n",
      "'VLOOKY': 0.978111\n",
      "'VLOOKZ': -0.192560\n",
      "'RADIANCE': 0.4484\n",
      "'TB': 95.856\n",
      "'CLAT': 8.90937\n",
      "'CLON': 263.37909\n",
      "'CEMIS': 2.95260\n",
      "'CSUNZEN': 91.32641\n",
      "'CSUNAZI': 48.33062\n",
      "'CLOCTIME': 5.91361\n",
      "'QCA': 000\n",
      "'QGE': 012\n",
      "'QMI': 000\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# Enum for data fields\n",
    "FIELD = Enum(\"FIELD\",\n",
    "\t[\"DATE\", \"UTC\", \"JDATE\", \"ORBIT\", \"SUNDIST\",\n",
    "\t\"SUNLAT\", \"SUNLON\", \"SCLK\", \"SCLAT\", \"SCLON\",\n",
    "\t\"SCRAD\", \"SCALT\", \"EL_CMD\", \"AZ_CMD\", \"AF\",\n",
    "\t\"ORIENTLAT\", \"ORIENTATION\", \"C\", \"DET\", \"VLOOKX\",\n",
    "\t\"VLOOKY\", \"VLOOKZ\", \"RADIANCE\", \"TB\", \"CLAT\",\n",
    "\t\"CLON\", \"CEMIS\", \"CSUNZEN\", \"CSUNAZI\", \"CLOCTIME\",\n",
    "\t\"QCA\", \"QGE\", \"QMI\"], \n",
    "\tstart=0)\n",
    "\n",
    "FIELD_LIST = list(FIELD)\n",
    "\n",
    "tmp = ok_lines[0]\n",
    "\n",
    "# Split the line    \n",
    "values = tmp.strip().split(',')\n",
    "\n",
    "# Remove any whitespaces from the values\n",
    "values = [val.strip() for val in values]\n",
    "\n",
    "index = 0\n",
    "for val in values:\n",
    "    print(repr(FIELD_LIST[index].name) + \": \" + val)\n",
    "    index += 1\n",
    "\n",
    "job_values = [\n",
    "    values[FIELD.DATE.value], values[FIELD.UTC.value], float(values[FIELD.JDATE.value]),\n",
    "\tfloat(values[FIELD.ORBIT.value]), float(values[FIELD.SUNDIST.value]), float(values[FIELD.SUNLAT.value]),\n",
    "\tfloat(values[FIELD.SUNLON.value]), float(values[FIELD.SCLK.value]), float(values[FIELD.SCLAT.value]),\n",
    "\tfloat(values[FIELD.SCLON.value]), float(values[FIELD.SCRAD.value]), float(values[FIELD.SCALT.value]),\n",
    "\tfloat(values[FIELD.EL_CMD.value]), float(values[FIELD.AZ_CMD.value]), float(values[FIELD.AF.value]),\n",
    "\tfloat(values[FIELD.ORIENTLAT.value]), float(values[FIELD.ORIENTATION.value]), float(values[FIELD.C.value]),\n",
    "\tint(values[FIELD.DET.value]), float(values[FIELD.VLOOKX.value]), float(values[FIELD.VLOOKY.value]),\n",
    "\tfloat(values[FIELD.VLOOKZ.value]), float(values[FIELD.RADIANCE.value]), float(values[FIELD.TB.value]),\n",
    "\tfloat(values[FIELD.CLAT.value]), float(values[FIELD.CLON.value]), float(values[FIELD.CEMIS.value]),\n",
    "\tfloat(values[FIELD.CSUNZEN.value]), float(values[FIELD.CSUNAZI.value]), float(values[FIELD.CLOCTIME.value]),\n",
    "    float(values[FIELD.QCA.value]), int(values[FIELD.QGE.value]), int(values[FIELD.QMI.value])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1b85423-863e-4c8e-a363-de6cca128322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DATE': 62\n",
      "'UTC': 63\n",
      "'JDATE': 66\n",
      "'ORBIT': 53\n",
      "'SUNDIST': 56\n",
      "'SUNLAT': 57\n",
      "'SUNLON': 58\n",
      "'SCLK': 65\n",
      "'SCLAT': 56\n",
      "'SCLON': 58\n",
      "'SCRAD': 59\n",
      "'SCALT': 57\n",
      "'EL_CMD': 56\n",
      "'AZ_CMD': 56\n",
      "'AF': 52\n",
      "'ORIENTLAT': 57\n",
      "'ORIENTATION': 58\n",
      "'C': 50\n",
      "'DET': 50\n",
      "'VLOOKX': 57\n",
      "'VLOOKY': 57\n",
      "'VLOOKZ': 58\n",
      "'RADIANCE': 55\n",
      "'TB': 55\n",
      "'CLAT': 56\n",
      "'CLON': 58\n",
      "'CEMIS': 56\n",
      "'CSUNZEN': 57\n",
      "'CSUNAZI': 57\n",
      "'CLOCTIME': 56\n",
      "'QCA': 52\n",
      "'QGE': 52\n",
      "'QMI': 52\n",
      "Total size: 1867\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "index = 0\n",
    "size = 0\n",
    "for val in values:\n",
    "    tmp_size = sys.getsizeof(val)\n",
    "    print(repr(FIELD_LIST[index].name) + \": \" + repr(tmp_size))\n",
    "    index += 1\n",
    "    size += tmp_size\n",
    "\n",
    "print(\"Total size: \" + repr(size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10a1c745-6b4d-4933-b38b-f84ac814b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'JDATE': 24\n",
      "'ORBIT': 24\n",
      "'SUNDIST': 24\n",
      "'SUNLAT': 24\n",
      "'SUNLON': 24\n",
      "'SCLK': 24\n",
      "'SCLAT': 24\n",
      "'SCLON': 24\n",
      "'SCRAD': 24\n",
      "'SCALT': 24\n",
      "'EL_CMD': 24\n",
      "'AZ_CMD': 24\n",
      "'AF': 24\n",
      "'ORIENTLAT': 24\n",
      "'ORIENTATION': 24\n",
      "'C': 24\n",
      "'DET': 28\n",
      "'VLOOKX': 24\n",
      "'VLOOKY': 24\n",
      "'VLOOKZ': 24\n",
      "'RADIANCE': 24\n",
      "'TB': 24\n",
      "'CLAT': 24\n",
      "'CLON': 24\n",
      "'CEMIS': 24\n",
      "'CSUNZEN': 24\n",
      "'CSUNAZI': 24\n",
      "'CLOCTIME': 24\n",
      "'QCA': 24\n",
      "'QGE': 28\n",
      "'QMI': 24\n",
      "Total size: 752\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "size = 0\n",
    "\n",
    "new_job_values = job_values[2:]\n",
    "\n",
    "for val in new_job_values:\n",
    "    tmp_size = sys.getsizeof(val)\n",
    "    print(repr(FIELD_LIST[index].name) + \": \" + repr(tmp_size))\n",
    "    index += 1\n",
    "    size += tmp_size\n",
    "\n",
    "print(\"Total size: \" + repr(size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8753ac4d-d958-4fd9-b324-b0616258e35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New date: 28\n",
      "New utc: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"New date: \" + repr(sys.getsizeof(new_date)))\n",
    "print(\"New utc: \" + repr(sys.getsizeof(new_utc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dce6b3a-c446-4591-aacd-b77c5cae23e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257795\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/esthar/diviner_data/txt_files/useful_tabs.txt\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(filepath, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.split()\n",
    "        number = int(parts[-1])\n",
    "        count += number\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5e08a-e850-4422-b309-c3734990821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DateTime\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
